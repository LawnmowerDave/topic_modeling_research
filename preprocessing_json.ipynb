{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T11:29:52.342511Z",
     "start_time": "2018-05-07T11:29:50.385716Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "from dateutil import parser\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from util.util import load, cache\n",
    "from util.streamer import line_gen\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# don't condense large numbers to scientific notation\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "filenames = glob(\"data/BTC/json/*.jsonl\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T11:37:28.909112Z",
     "start_time": "2018-05-07T11:33:15.478609Z"
    }
   },
   "outputs": [],
   "source": [
    "total_posts = 0\n",
    "total_reple = 0\n",
    "preprocessed_data = {}\n",
    "preprocessed_data['user_network'] = nx.DiGraph()\n",
    "\n",
    "# a dictionary of user's posts, their time, quantity\n",
    "# accessed via preprocessed_data[field][user_name]\n",
    "preprocessed_data['time_posts'] = defaultdict(list)\n",
    "preprocessed_data['user_time_posts'] = defaultdict(dict)\n",
    "preprocessed_data['user_posts'] = defaultdict(list)\n",
    "preprocessed_data['user_posts_num'] = defaultdict(int)\n",
    "preprocessed_data['get_comment_num'] = defaultdict(int)\n",
    "preprocessed_data['write_comment_num'] = defaultdict(int)\n",
    "\n",
    "# various Twitter metadata\n",
    "preprocessed_data['verified'] = defaultdict(bool)\n",
    "\n",
    "preprocessed_data['retweet_count'] = defaultdict(list)\n",
    "preprocessed_data['followers_count'] = defaultdict(int)\n",
    "preprocessed_data['favorite_count'] = defaultdict(int)\n",
    "\n",
    "preprocessed_data['posts'] = []\n",
    "voca = set()\n",
    "word_freq = Counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 400,000 tweets is the max my machine can load into RAM (total dataset is about 16 M)\n",
    "# df = pd.concat([pd.read_json(filename, nrows=n_tweets/len(filenames), lines=True) for filename in filenames])\n",
    "df = load('btc_data')\n",
    "\n",
    "df = df.sort_values(by='in_reply_to_user_id')\n",
    "\n",
    "# convert strings to datetime objects\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], format='%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts:  67504\n",
      "comments:  15074\n"
     ]
    }
   ],
   "source": [
    "print('posts: ', len(df[df['in_reply_to_user_id'].isna()]))\n",
    "print('comments: ', len(df[df['in_reply_to_user_id'].notna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_counts = {}\n",
    "\n",
    "# for row in df.itertuples():\n",
    "#     if not row.created_at.year in date_counts:\n",
    "#         date_counts[row.created_at.year] = 1\n",
    "#     else:\n",
    "#         date_counts[row.created_at.year] += 1\n",
    "\n",
    "# print(date_counts)\n",
    "# plt.plot(sorted(date_counts.keys()), sorted(date_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_text', 'created_at', 'in_reply_to_user_id', 'retweet_count',\n",
       "       'favorite_count', 'id', 'verified', 'followers_count', 'retweet_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts: 100.00% done\n",
      "Number of unique words: 47416\n"
     ]
    }
   ],
   "source": [
    "# word_freq_file_name = 'pkl/word_freq_pkl' \n",
    "\n",
    "# # load cached result. Important: Make sure the number of tweets used is the same in the df!\n",
    "# if os.path.exists(word_freq_file_name):\n",
    "#     with open(word_freq_file_name, 'rb') as f:\n",
    "#         word_freq = pickle.load(f)\n",
    "# else:\n",
    "\n",
    "#     with open(word_freq_file_name, 'wb') as f:\n",
    "#         pickle.dump(word_freq, f)\n",
    "\n",
    "# update word count\n",
    "for i, text in enumerate(df[\"full_text\"]):\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"\\rposts: {i/len(df) * 100:.2f}% done\", end='')\n",
    "        \n",
    "    text_body = text\n",
    "    word_freq.update(text_body)\n",
    "\n",
    "print(f\"\\rposts: {100:.2f}% done\", end='')\n",
    "print()\n",
    "print(\"Number of unique words:\", len(word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% done 5467 nodes and 6257 edges\n",
      "pickling...\n",
      "Number of unique vocabulary words 7325\n",
      "\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "comments_processed_dict = {}\n",
    "retweets_processed_dict = {}\n",
    "\n",
    "counter = 0\n",
    "\n",
    "voca = set()\n",
    "\n",
    "# only loop through posts. Comments will be counted if the user is found\n",
    "# to be in the comments_user_dict \n",
    "for i, post in enumerate(df[df['in_reply_to_user_id'].isna()].itertuples()):\n",
    "\n",
    "    post_user = post.id\n",
    "\n",
    "    # add metadata\n",
    "    preprocessed_data['verified'][post_user] = post.verified\n",
    "    preprocessed_data['followers_count'][post_user] = post.followers_count\n",
    "    preprocessed_data['favorite_count'][post_user] = post.favorite_count\n",
    "\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"\\r{i/len(df[df['in_reply_to_user_id'].isna()]) * 100:.2f}% done\", end='')\n",
    "        print(f\"\\r{preprocessed_data['user_network']}\", end='')\n",
    "\n",
    "\n",
    "    post_body = post.full_text\n",
    "    post_body = [w for w in post_body if word_freq[w] >= 10]\n",
    "    \n",
    "    if len(post_body) < 5:\n",
    "        continue\n",
    "\n",
    "    voca.update(post_body)\n",
    "    \n",
    "    posted_time = post.created_at\n",
    "\n",
    "    # retweet data\n",
    "    if posted_time in preprocessed_data['retweet_count'][post_user]:\n",
    "        preprocessed_data['retweet_count'][post_user].append(post.retweet_count)\n",
    "    else:\n",
    "        preprocessed_data['retweet_count'][post_user] = [post.retweet_count]\n",
    "    \n",
    "    preprocessed_data['user_posts'][post_user].append(post_body)\n",
    "    preprocessed_data['user_posts_num'][post_user] += 1\n",
    "    preprocessed_data['time_posts'][posted_time].append(post_body)\n",
    "    if posted_time in preprocessed_data['user_time_posts'][post_user]:\n",
    "        preprocessed_data['user_time_posts'][post_user][posted_time].append(post_body)\n",
    "    else:\n",
    "        preprocessed_data['user_time_posts'][post_user][posted_time] = [post_body]\n",
    "        \n",
    "    preprocessed_data['posts'].append(post_body)\n",
    "\n",
    "    if str(post_user) in comments_processed_dict:\n",
    "        continue\n",
    "\n",
    "    # Link comments\n",
    "    post_comments = df[df['in_reply_to_user_id'] == post_user]\n",
    "    \n",
    "    for comment in post_comments.itertuples():\n",
    "\n",
    "        comments_processed_dict[str(post_user)] = True\n",
    "\n",
    "        comment_body = comment.full_text\n",
    "\n",
    "        comment_body = [w for w in comment_body if word_freq[w] >= 10]\n",
    "        if len(comment_body) < 5:\n",
    "            continue\n",
    "        voca.update(comment_body)\n",
    "        comment_user = comment.id\n",
    "        comment_time = comment.created_at\n",
    "            \n",
    "        preprocessed_data['user_posts'][comment_user].append(comment_body)\n",
    "        preprocessed_data['time_posts'][comment_time].append(comment_body)\n",
    "        if posted_time in preprocessed_data['user_time_posts'][post_user]:\n",
    "            preprocessed_data['user_time_posts'][post_user][posted_time].append(post_body)\n",
    "        else:\n",
    "            preprocessed_data['user_time_posts'][post_user][posted_time] = [post_body]\n",
    "        \n",
    "        preprocessed_data['posts'].append(comment_body)\n",
    "        preprocessed_data['user_network'].add_edge(comment_user, post_user)\n",
    "        preprocessed_data['get_comment_num'][post_user] += 1\n",
    "        preprocessed_data['write_comment_num'][comment_user] += 1\n",
    "\n",
    "    \"\"\"\n",
    "    Link retweets\n",
    "\n",
    "    Currently only going to draw a connection on the graph without doing anything \n",
    "    extra like adding the text to the posts as it would just be redundant information.\n",
    "    \"\"\" \n",
    "    if str(post_user) in retweets_processed_dict:\n",
    "        continue\n",
    "\n",
    "    post_retweets = df[df['retweet_id'] == post_user]\n",
    "\n",
    "    for retweet in post_retweets.itertuples():\n",
    "        retweets_processed_dict[str(post_user)] = True\n",
    "\n",
    "        retweet_user = retweet.id\n",
    "        retweet_time = retweet.created_at\n",
    "        \n",
    "        preprocessed_data['user_network'].add_edge(retweet_user, post_user)\n",
    "    \n",
    "        \n",
    "\n",
    "print(f\"\\r{100:.2f}% done\", end='')\n",
    "print(\"\\npickling...\")\n",
    "\n",
    "voca = list(voca)\n",
    "preprocessed_data['voca'] = voca\n",
    "preprocessed_data['word_freq'] = word_freq\n",
    "with open(\"pkl/preprocessed_bitcoin.pkl\", 'wb') as f:\n",
    "    pickle.dump(preprocessed_data, f)\n",
    "\n",
    "print(\"Number of unique vocabulary words\", len(voca))\n",
    "print()\n",
    "print(\"finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67503"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67504"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['in_reply_to_user_id'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 5500 nodes and 6289 edges\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_data['user_network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_shell(preprocessed_data[\"user_network\"], with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = [len(a) for a in list(preprocessed_data['user_network'].adj.values())]\n",
    "# print(max(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac5807ccc56803d53b6c0dc06a78365d93d8e4c11f3c7f359a83bbe035ca0794"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
